# Optimizing an ML Pipeline in Azure

## Overview
This project is part of the Udacity Azure ML Nanodegree.
In this project, we build and optimize an Azure ML pipeline using the Python SDK and a provided Scikit-learn model.
This model is then compared to an Azure AutoML run.

## Summary
This dataset contains data about bank marketing. We seek to predict if a customer subscribed to a fixed term deposit, which is a column 'y' in our data.
So, our target column or label column will be 'y' which we going to predict.
The best performing model was "VotingEnsemble" with accuracy of 0.9143. The model "StackEnsemble" which has a metric "0.9134" is also closed to "VotingEnsemble."

## Scikit-learn Pipeline
**Explain the pipeline architecture, including data, hyperparameter tuning, and classification algorithm.**
I loaded the data from the provided source url with TabularDatasetFactory. The data are then cleaned and normalized with training set of 20 percent and
test set of 80 percent. It used the LogisticRegression to train the model.

As we are going to predict for Discrete, I am using the discreate hyper parameter.
I am using RandomParameterSampling with choice of max iteration from 10,20 or 30. And for RegularizationValue of C uniform from 0.5 to 1.
I am using BanditPolicy as the early stopping policy with slack_factor=0.1,evaluation_interval=1 and delay_evaluation=5.

**What are the benefits of the parameter sampler you chose?**
For the Regularization value I choosed uniform(0.5,1) and for Max iteration it will choose from (10,20,30).
The purpose is to tune these hyperparameters using HyperDrive.

**What are the benefits of the early stopping policy you chose?**
I used BanditPolicy as the early stopping policy. On this one , the early termination is based on slack factor and evaluation interval and delay evaluation.
The early stopping policy like 'BanditPolicy' helps to avoid overfitting when training a learner with an iterative method.


## AutoML
**In 1-2 sentences, describe the model and hyperparameters generated by AutoML.**
For the AutoML, I have created a AutoMLConfig and submit the experiment. The Primary metric used is 'Accuracy' and the task was 'Classification'.
I used the compute target that created from SDK and also passed the 80% of available data as the training data. I have also used the 4 cross validation.


## Pipeline comparison
**Compare the two models and their performance. What are the differences in accuracy? In architecture? If there was a difference, why do you think there was one?**
For HyperDrive , the accuracy I got is: 0.907 where as for AutoML I got accuracy of 0.9143. It looks like there is not much difference on Accuracy, however the hyperdrive was time consuming and also complex because we have to give the regularization value and the the max iteration we want to iterate and also need to specify the early termination policy. Whereas in AutoML, its simple and it automatically tune the Hyperparameter.AutoML also automatically tried different models and at the end gives the best model with high accuracy.

## Future work
**What are some areas of improvement for future experiments? Why might these improvements help the model?**
For future experiments, In HyperDrive, we can try with different regularization and increase the iteration value to see if we can get better result.
In case of AutoML, we can try with the UI without the SDK and compare with the SDK value.And also change by different value of Cross validation.
